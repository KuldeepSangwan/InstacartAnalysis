{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "from F1Optimizer import F1Optimizer\n",
    "import random\n",
    "import time\n",
    "tqdm.pandas()\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final File\n",
    "<p>The final file has been created by keeping the production of model in mind by that i mean is we would take very less number parameter from the user and there are some parameters like days_since_prior_order, order_number that we have choosen randomly and also there are some parameters like order_dow, order_hour_of_day that we have taken from current timestamp.</p>\n",
    "<p>In final file i have created two function - Prediction(), Prediction_with_Metric()\n",
    "<p>In Prediction(), we take just a user_id as input and output the products that need to be recommended.</p>\n",
    "<p>In Prediction_with_Metric(), i take list of users and list of actual produts that they are gonne order and the output for this is mean f1 score to get rough idea of how model performs.</p>\n",
    "<p>I am not predicting None in the Production model.As i think it would look a little bit odd to user.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction(user_id):\n",
    "    pred=[]\n",
    "    frst1 = time.time()\n",
    "    dow = datetime.now().month\n",
    "    hour = datetime.now().hour\n",
    "    here1 = joblib.load('final_sub/user_prod_orderdow.pkl')\n",
    "    here1 = here1[here1['user_id']==user_id]\n",
    "    if here1.shape[0]!=0:\n",
    "        here1 = here1[here1['user_id']==user_id]\n",
    "        list_days = joblib.load('final_sub/list_days.pkl')\n",
    "        products = joblib.load('final_sub/products.pkl')\n",
    "        orders_prior_department_reordered = joblib.load('final_sub/orders_prior_department_reordered.pkl')\n",
    "        orders_prior_aisle_reordered = joblib.load('final_sub/orders_prior_aisle_reordered.pkl')\n",
    "        productFeat = joblib.load('final_sub/productFeat.pkl')\n",
    "        user_feat1 = joblib.load('final_sub/user_feat1.pkl')\n",
    "        product_features1 = joblib.load('final_sub/product_features1.pkl')\n",
    "        user_product_order = joblib.load('final_sub/user_product_order.pkl')\n",
    "        temp_data = joblib.load('final_sub/order_prod_addToCart.pkl')\n",
    "        product_embeddings = joblib.load('final_sub/product_embeddings.pkl')\n",
    "    \n",
    "        \n",
    "        def get_order_dow(x):\n",
    "            if any(x['order_dow']==dow):\n",
    "                return x[x['order_dow']==dow]\n",
    "            else:\n",
    "                a = x[x['user_id']==user_id].head(1)\n",
    "                a['order_dow']=dow\n",
    "                a['week_product_reordered']=0\n",
    "                a['week_product_ordered']=0\n",
    "                a['week_product_reordered_ration']=0\n",
    "                return a\n",
    "\n",
    "        am = here1.groupby('product_id').apply(get_order_dow)\n",
    "        convert_dict = {'user_id': int,\n",
    "                        'product_id': int,\n",
    "                        'order_dow': int,\n",
    "                        'week_product_reordered': int,\n",
    "                        'week_product_ordered': int,\n",
    "                        'week_product_reordered_ration': float,\n",
    "                       }\n",
    "        data = am.astype(convert_dict)\n",
    "        data.reset_index(drop=True, inplace=True) \n",
    "        data = data.merge(list_days,on=[\"user_id\", 'product_id'])\n",
    "        # del list_days\n",
    "        data = data.merge(products,on=\"product_id\")\n",
    "        data = data.merge(orders_prior_department_reordered,on=['user_id', 'department_id'])\n",
    "        data = data.merge(orders_prior_aisle_reordered,on=['user_id', 'aisle_id'])\n",
    "\n",
    "        data = data.merge(productFeat,on='product_id')\n",
    "        data = data.merge(user_feat1,on='user_id')\n",
    "        data = data.merge(product_features1,on='product_id')\n",
    "        data = data.merge(user_product_order,on=['user_id','product_id'])\n",
    "        data = data.merge(temp_data,on=['user_id','product_id'])\n",
    "        data = data.merge(product_embeddings,on='product_id')\n",
    "\n",
    "        del list_days, products, orders_prior_department_reordered, orders_prior_aisle_reordered, productFeat, user_feat1, product_features1, user_product_order, temp_data, product_embeddings\n",
    "\n",
    "        # gave random value for some of the parameters\n",
    "        data['days_since_prior_order']=float(random.randint(1, 30))\n",
    "        data['order_number']=random.randint(10, 20)\n",
    "        data['order_hour_of_day']=hour\n",
    "\n",
    "        test = data[['product_id', 'user_id', 'order_number', 'order_dow',\n",
    "           'order_hour_of_day', 'days_since_prior_order', 'aisle_id',\n",
    "           'department_id', 'unique_prod_in_aisle', 'aisle_product_reordered',\n",
    "           'unique_prod_in_department', 'department_product_reordered',\n",
    "           'number_of_unique_users_for_product',\n",
    "           'number_of_unique_users_for_product_reordered', '0', '1', '2', '3', '4',\n",
    "           '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17',\n",
    "           '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',\n",
    "           '30', '31', 'days_before_product_ordered-1',\n",
    "           'days_before_product_ordered-4', 'days_before_product_ordered-2',\n",
    "           'days_before_product_ordered_mean', 'days_before_product_ordered-3',\n",
    "           'days_before_product_ordered_median', 'prod_orders',\n",
    "           'prod_ordersBYtotal_orders', 'product_ordered_last',\n",
    "           'product_ordered_first', 'prod_min_orderNumber', 'prod_max_orderNumber',\n",
    "           'prod_cart_mean', 'days_since_prior_order_mean', 'order_dow_mean',\n",
    "           'order_hour_of_day_mean', 'add_to_cart_order_inverse_mean',\n",
    "           'add_to_cart_order_relative_mean', 'reordered_sum',\n",
    "           'week_product_reordered', 'week_product_ordered',\n",
    "           'week_product_reordered_ration', 'user_orders_count', 'user_since',\n",
    "           'user_mean_days_since_prior_order',\n",
    "           'user_median_days_since_prior_order', 'unique_prod',\n",
    "           'NumberTimeProductsOrdered', 'user_reorder_ratio',\n",
    "           'Avergae_Basket_size']]\n",
    "\n",
    "        bst = joblib.load('final_sub/model.pkl') \n",
    "        pred_Xcv = bst.predict(xgb.DMatrix(test))\n",
    "\n",
    "        data['pred'] = pred_Xcv\n",
    "        test_pred = data[['user_id','product_name','product_id','pred']].groupby('user_id').agg({'product_id': list,'product_name': list, 'pred': list})\n",
    "\n",
    "        def sort_values(row):  \n",
    "            ok = np.argsort(np.array(row['pred']))\n",
    "            test_pred.at[row.name,'product_id']=[row['product_id'][i] for i in ok][::-1]\n",
    "            test_pred.at[row.name,'product_name']=[row['product_name'][i] for i in ok][::-1]\n",
    "            test_pred.at[row.name,'pred'] = [row['pred'][i] for i in ok][::-1]\n",
    "\n",
    "        test_pred.apply(sort_values,axis=1)\n",
    "\n",
    "        for index, row in test_pred.iterrows():\n",
    "            opt=F1Optimizer.maximize_expectation(row.pred)\n",
    "            best_k=opt[0]\n",
    "            pred=test_pred[test_pred.index==index]['product_id'].values[0][:best_k]\n",
    "    else:\n",
    "        Top_prod_DOW_Hour = joblib.load('final_sub/Top_prod_DOW_Hour.pkl')\n",
    "        pred = Top_prod_DOW_Hour[(Top_prod_DOW_Hour['order_dow']==dow) & (Top_prod_DOW_Hour['order_hour_of_day']==hour)]['top_prod'].values[0]\n",
    "        if not pred:\n",
    "            Top_prod_Hour = joblib.load('final_sub/Top_prod_Hour.pkl')\n",
    "            pred = Top_prod_Hour[Top_prod_DOW_Hour['order_hour_of_day']==hour]['top_prod'].values[0]\n",
    "        \n",
    "    print('Time it took to Predct(sec): ', time.time() - frst1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to Predct(sec):  18.550846338272095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24852,\n",
       " 47209,\n",
       " 18523,\n",
       " 16589,\n",
       " 19156,\n",
       " 32792,\n",
       " 1559,\n",
       " 33754,\n",
       " 21709,\n",
       " 22825,\n",
       " 39928,\n",
       " 7781,\n",
       " 20785,\n",
       " 19057,\n",
       " 42342,\n",
       " 45948,\n",
       " 27413,\n",
       " 22124]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_predicted = Prediction(2)\n",
    "products_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction_with_Metric(user_ids,actual_prods):\n",
    "    predict_prods = []\n",
    "    pred = []\n",
    "    frst1 = time.time()\n",
    "    dow = datetime.now().month\n",
    "    hour = datetime.now().hour\n",
    "    here1 = joblib.load('final_sub/user_prod_orderdow.pkl')\n",
    "    list_days = joblib.load('final_sub/list_days.pkl')\n",
    "    products = joblib.load('final_sub/products.pkl')\n",
    "    orders_prior_department_reordered = joblib.load('final_sub/orders_prior_department_reordered.pkl')\n",
    "    orders_prior_aisle_reordered = joblib.load('final_sub/orders_prior_aisle_reordered.pkl')\n",
    "    productFeat = joblib.load('final_sub/productFeat.pkl')\n",
    "    user_feat1 = joblib.load('final_sub/user_feat1.pkl')\n",
    "    product_features1 = joblib.load('final_sub/product_features1.pkl')\n",
    "    user_product_order = joblib.load('final_sub/user_product_order.pkl')\n",
    "    temp_data = joblib.load('final_sub/order_prod_addToCart.pkl')\n",
    "    product_embeddings = joblib.load('final_sub/product_embeddings.pkl')\n",
    "    for user_id in user_ids:\n",
    "        her = here1[here1['user_id']==user_id]\n",
    "        if here1.shape[0]!=0:\n",
    "            her = here1[here1['user_id']==user_id]\n",
    "\n",
    "            def get_order_dow(x):\n",
    "                if any(x['order_dow']==dow):\n",
    "                    return x[x['order_dow']==dow]\n",
    "                else:\n",
    "                    a = x[x['user_id']==user_id].head(1)\n",
    "                    a['order_dow']=dow\n",
    "                    a['week_product_reordered']=0\n",
    "                    a['week_product_ordered']=0\n",
    "                    a['week_product_reordered_ration']=0\n",
    "                    return a\n",
    "\n",
    "            am = her.groupby('product_id').apply(get_order_dow)\n",
    "            convert_dict = {'user_id': int,\n",
    "                            'product_id': int,\n",
    "                            'order_dow': int,\n",
    "                            'week_product_reordered': int,\n",
    "                            'week_product_ordered': int,\n",
    "                            'week_product_reordered_ration': float,\n",
    "                           }\n",
    "            data = am.astype(convert_dict)\n",
    "            data.reset_index(drop=True, inplace=True) \n",
    "            data = data.merge(list_days,on=[\"user_id\", 'product_id'])\n",
    "            data = data.merge(products,on=\"product_id\")\n",
    "            data = data.merge(orders_prior_department_reordered,on=['user_id', 'department_id'])\n",
    "            data = data.merge(orders_prior_aisle_reordered,on=['user_id', 'aisle_id'])\n",
    "\n",
    "            data = data.merge(productFeat,on='product_id')\n",
    "            data = data.merge(user_feat1,on='user_id')\n",
    "            data = data.merge(product_features1,on='product_id')\n",
    "            data = data.merge(user_product_order,on=['user_id','product_id'])\n",
    "            data = data.merge(temp_data,on=['user_id','product_id'])\n",
    "            data = data.merge(product_embeddings,on='product_id')\n",
    "\n",
    "            # gave random value for some of the parameters\n",
    "            data['days_since_prior_order']=float(random.randint(1, 30))\n",
    "            data['order_number']=random.randint(10, 20)\n",
    "            data['order_hour_of_day']=hour\n",
    "\n",
    "            test = data[['product_id', 'user_id', 'order_number', 'order_dow',\n",
    "               'order_hour_of_day', 'days_since_prior_order', 'aisle_id',\n",
    "               'department_id', 'unique_prod_in_aisle', 'aisle_product_reordered',\n",
    "               'unique_prod_in_department', 'department_product_reordered',\n",
    "               'number_of_unique_users_for_product',\n",
    "               'number_of_unique_users_for_product_reordered', '0', '1', '2', '3', '4',\n",
    "               '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17',\n",
    "               '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',\n",
    "               '30', '31', 'days_before_product_ordered-1',\n",
    "               'days_before_product_ordered-4', 'days_before_product_ordered-2',\n",
    "               'days_before_product_ordered_mean', 'days_before_product_ordered-3',\n",
    "               'days_before_product_ordered_median', 'prod_orders',\n",
    "               'prod_ordersBYtotal_orders', 'product_ordered_last',\n",
    "               'product_ordered_first', 'prod_min_orderNumber', 'prod_max_orderNumber',\n",
    "               'prod_cart_mean', 'days_since_prior_order_mean', 'order_dow_mean',\n",
    "               'order_hour_of_day_mean', 'add_to_cart_order_inverse_mean',\n",
    "               'add_to_cart_order_relative_mean', 'reordered_sum',\n",
    "               'week_product_reordered', 'week_product_ordered',\n",
    "               'week_product_reordered_ration', 'user_orders_count', 'user_since',\n",
    "               'user_mean_days_since_prior_order',\n",
    "               'user_median_days_since_prior_order', 'unique_prod',\n",
    "               'NumberTimeProductsOrdered', 'user_reorder_ratio',\n",
    "               'Avergae_Basket_size']]\n",
    "\n",
    "            bst = joblib.load('final_sub/model.pkl') \n",
    "            pred_Xcv = bst.predict(xgb.DMatrix(test))\n",
    "\n",
    "            data['pred'] = pred_Xcv\n",
    "            test_pred = data[['user_id','product_name','product_id','pred']].groupby('user_id').agg({'product_id': list,'product_name': list, 'pred': list})\n",
    "\n",
    "            def sort_values(row):  \n",
    "                ok = np.argsort(np.array(row['pred']))\n",
    "                test_pred.at[row.name,'product_id']=[row['product_id'][i] for i in ok][::-1]\n",
    "                test_pred.at[row.name,'pred'] = [row['pred'][i] for i in ok][::-1]\n",
    "\n",
    "            test_pred.apply(sort_values,axis=1)\n",
    "\n",
    "            for index, row in test_pred.iterrows():\n",
    "                opt=F1Optimizer.maximize_expectation(row.pred)\n",
    "                best_k=opt[0]\n",
    "                pred=test_pred[test_pred.index==index]['product_id'].values[0][:best_k]\n",
    "        else:\n",
    "            Top_prod_DOW_Hour = joblib.load('final_sub/Top_prod_DOW_Hour.pkl')\n",
    "            pred = Top_prod_DOW_Hour[(Top_prod_DOW_Hour['order_dow']==dow) & (Top_prod_DOW_Hour['order_hour_of_day']==hour)]['top_prod'].values[0]\n",
    "            if not pred:\n",
    "                Top_prod_Hour = joblib.load('final_sub/Top_prod_Hour.pkl')\n",
    "                pred = Top_prod_Hour[Top_prod_DOW_Hour['order_hour_of_day']==hour]['top_prod'].values[0]\n",
    "        predict_prods.append(pred)\n",
    "    def f1_score_single(y_true, y_pred):\n",
    "        y_true = set(y_true)\n",
    "        y_pred = set(y_pred)\n",
    "        cross_size = len(y_true & y_pred)\n",
    "        if cross_size == 0: return 0.\n",
    "        p = 1. * cross_size / len(y_pred)\n",
    "        r = 1. * cross_size / len(y_true)\n",
    "        return 2 * p * r / (p + r)\n",
    "\n",
    "    def f1_score(y_true, y_pred):\n",
    "        return np.mean([f1_score_single(x, y) for x, y in zip(y_true, y_pred)])\n",
    "    mean_f1score = f1_score(actual_prods, predict_prods)\n",
    "    return mean_f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529411764705882"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids=[1,5,13]\n",
    "actual_prods=[[196, 46149, 25133,49235,38928,26088,10258,39657,26405,13032],[40706,21616,15349,21413],[27086,4210,1199345937,27435]]\n",
    "mean_f1score= Prediction_with_Metric(user_ids,actual_prods)\n",
    "mean_f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
