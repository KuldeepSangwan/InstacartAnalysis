{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "<p>Instacart, a grocery order and the delivery app with over 500 Million products and 40000 stores serves across U.S. & Canada. Instacart provides a user experience where you will get product recommendation based on your previous orders.</p>\n",
    "<p>Instacart provided us with transactional data of customer orders over time to predict which previously purchased products will be in a user’s next order. This data is open-sourced and given as a Kaggle challenge.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World / Business Objectives and Constraints\n",
    "<p>The objective is to predict which products will be in a user’s next order. The dataset is anonymized and contains a sample of over 3 million grocery orders from more than 200,000 Instacart users. For each user, Instacart provided between 4 and 100 of their orders, along with the sequence in which products were placed in the cart.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ml formulation of business problem\n",
    "<p>For the user to get product recommendations based on his past N orders, we need to observe patterns and generate rules which will give recommendations with high probability. Since we have over 3 Million data points, we need to automate this learning process and using Machine Learning we can achieve this to give probabilistic prediction. Machine Learning works better on large sets of data and generates rules from patterns learned from features.</p>\n",
    "<p>Other Alternative would be a rule based system, which works best when we know the rules. But it’s very difficult to generate rules by going over all data samples manually and make sense of the patterns. This can’t guarantee in high predictive power</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Metric to use\n",
    "<p> from the problem statement perspective we need to recommend a product to the user and cost of not recommending a product(which is gonne be bought) is less.</p>\n",
    "<p>As there are 4 metrics that can be used Accuracy, LogLoss, Roc_AUC Curve, F1 Score</p>\n",
    "<p><b>why not Accuracy -</b></p> \n",
    "\t<ul>\n",
    "\t<li>Doesn't care about probablitites</li>\n",
    "\t<li>it gives equal importance to negative class but from our problem the positive class is more important</li>\n",
    "\t</ul>\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "<p><b>why not LogLoss - </b></p>\n",
    "\t<ul>\n",
    "\t<li>it gives equal importance to negative class but from our problem the positive class is more important</li>\n",
    "\t</ul>\n",
    "\t\n",
    "\n",
    "<p><b>why not ROC_AUC curve -</b></p>\n",
    "\t<p>if a model is performing bad for true positive class(imbalnced data, Positive has less data points) then it is still gonne give a decent score to that model.\n",
    "\texample - </p>\n",
    "\t\t<p>model (1) predicts 5 positives out of 100 true positives in a dataset of size 10K observations, while another model (2) predicts 90 positives out of 100 true positives.</p>\n",
    "\t\t<p>F1 score for model (1) = 2*(1)*(0.1)/1.1 = 0.095</p>\n",
    "\t\t<p>F1 score for model (2) = 2*(1)*(0.9)/1.9 = 0.947</p>\n",
    "\t\t\n",
    "\t\t<p>ROC-AUC for model (1) = 0.5</p>\n",
    "\t\t<p>ROC-AUC for model (2) = 0.93</p>\n",
    "\t\t\n",
    "<p><b>why F1 score -</b></p> \n",
    "\t<ul>\n",
    "\t<li>Good with imbalnced data</li>\n",
    "\t<li>Can do the tuninf of the threhold</li>\n",
    "\t<li>Care more about the True positive class, which we want in our problem statement</li>\n",
    "\t</ul>\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "path = \"Data\"\n",
    "aisles = pd.read_csv(os.path.join(path, \"aisles.csv\"), dtype={'aisle_id': np.uint8, 'aisle':'category'})\n",
    "departments = pd.read_csv(os.path.join(path, \"departments.csv\"), dtype={'department_id':np.uint8, 'department': 'category'})\n",
    "order_prior = pd.read_csv(os.path.join(path, \"order_products__prior.csv\"), dtype={'order_id': np.uint32,\n",
    "                                                                                  'product_id': np.uint16,\n",
    "                                                                                  'add_to_cart_order':np.uint8,\n",
    "                                                                                  'reordered': bool})\n",
    "order_train = pd.read_csv(os.path.join(path, \"order_products__train.csv\"), dtype={'order_id': np.uint32,\n",
    "                                                                                  'product_id': np.uint16,\n",
    "                                                                                  'add_to_cart_order':np.uint8,\n",
    "                                                                                  'reordered': bool})\n",
    "orders = pd.read_csv(os.path.join(path, \"orders.csv\"), dtype={'order_id':np.uint32,\n",
    "                                                              'user_id': np.uint32,\n",
    "                                                              'eval_set': 'category',\n",
    "                                                              'order_number':np.uint8,\n",
    "                                                              'order_dow': np.uint8,\n",
    "                                                              'order_hour_of_day': np.uint8\n",
    "                                                              })\n",
    "products = pd.read_csv(os.path.join(path, \"products.csv\"), dtype={'product_id': np.uint16,\n",
    "                                                                  'aisle_id': np.uint8,\n",
    "                                                                  'department_id': np.uint8})\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1187899</td>\n",
       "      <td>196</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1187899</td>\n",
       "      <td>14084</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1187899</td>\n",
       "      <td>12427</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1187899</td>\n",
       "      <td>26088</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1187899</td>\n",
       "      <td>26405</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id eval_set  reordered\n",
       "0   1187899         196    train       True\n",
       "1   1187899       14084    train      False\n",
       "2   1187899       12427    train      False\n",
       "3   1187899       26088    train       True\n",
       "4   1187899       26405    train       True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order_id and Product_id with no duplicates, we take only orders from prior that are in train data\n",
    "# so we create a train model dataframe, we are gonne merge all the feature into this, and rows number would gonne be same after inserting all the features\n",
    "\n",
    "order_train1 = order_train.copy()\n",
    "order_train1.drop(['add_to_cart_order'], axis=1, inplace=True)\n",
    "labels1 = orders[orders['eval_set']==\"prior\"].merge(order_prior,on='order_id')[['user_id','product_id']].drop_duplicates()\n",
    "order_label = labels1.merge(orders[(orders.eval_set==\"train\") | (orders.eval_set==\"test\")], on=\"user_id\")[['order_id','product_id','eval_set']]\n",
    "labels = order_label.merge(order_train1, how='left',on=['order_id','product_id'])\n",
    "labels.reordered.fillna(False, inplace=True)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>days_before_product_ordered-1</th>\n",
       "      <th>days_before_product_ordered-4</th>\n",
       "      <th>days_before_product_ordered-2</th>\n",
       "      <th>days_before_product_ordered_mean</th>\n",
       "      <th>days_before_product_ordered-3</th>\n",
       "      <th>days_before_product_ordered_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.0</td>\n",
       "      <td>107.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  product_id  days_before_product_ordered-1  \\\n",
       "0        1         196                           30.0   \n",
       "1        1       10258                           30.0   \n",
       "2        1       10326                            NaN   \n",
       "3        1       12427                           30.0   \n",
       "4        1       13032                           44.0   \n",
       "\n",
       "   days_before_product_ordered-4  days_before_product_ordered-2  \\\n",
       "0                           20.0                            0.0   \n",
       "1                           20.0                            0.0   \n",
       "2                            NaN                            NaN   \n",
       "3                           20.0                            0.0   \n",
       "4                            NaN                          117.0   \n",
       "\n",
       "   days_before_product_ordered_mean  days_before_product_ordered-3  \\\n",
       "0                        102.333333                           14.0   \n",
       "1                        102.333333                           14.0   \n",
       "2                         93.000000                            NaN   \n",
       "3                        102.333333                           14.0   \n",
       "4                        107.666667                            NaN   \n",
       "\n",
       "   days_before_product_ordered_median  \n",
       "0                               112.0  \n",
       "1                               112.0  \n",
       "2                                93.0  \n",
       "3                               112.0  \n",
       "4                               132.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features on user_id, Product_id and days_since_prior_order\n",
    "\n",
    "merged = orders.merge(order_prior,on='order_id').sort_values(['user_id','order_number'])\n",
    "cumulative_sum_days_since_prior_order = merged.copy()\n",
    "merged_cum_sum = cumulative_sum_days_since_prihe or_order.groupby('order_id')[['user_id','days_since_prior_order','order_number']].agg(max).sort_values(['user_id','order_number'])\n",
    "temp = merged_cum_sum.groupby(['user_id']).agg({'days_since_prior_order':'cumsum'}).rename(columns={'days_since_prior_order':\"days_since_prior_order_cum_sum\"})\n",
    "merged_with_cum_sum = merged_cum_sum.merge(temp,on='order_id')\n",
    "merged_with_cum_sum_prod = merged_with_cum_sum.merge(merged[['order_id','product_id']],on='order_id')\n",
    "list_days = merged_with_cum_sum_prod.groupby(['user_id','product_id'])['days_since_prior_order_cum_sum'].progress_apply(list)\n",
    "list_days = list_days.to_frame(name='cum_sum days_before_product_ordered' )\n",
    "\n",
    "list_days['days_before_product_ordered-1'] = list_days.groupby(['user_id','product_id']).progress_apply(lambda x: np.subtract(list(x['cum_sum days_before_product_ordered'].values)[0][-1],list(x['cum_sum days_before_product_ordered'].values)[0][-2]) if len(list(x['cum_sum days_before_product_ordered'].values)[0]) > 1 and list(x['cum_sum days_before_product_ordered'].values)[0][-2]>1 else list(x['cum_sum days_before_product_ordered'].values)[0][-1] if len(list(x['cum_sum days_before_product_ordered'].values)[0]) > 1 and np.isnan(list(x['cum_sum days_before_product_ordered'].values)[0][-2]) else np.NAN)\n",
    "list_days['days_before_product_ordered-2'] = list_days.groupby(['user_id','product_id']).progress_apply(lambda x: np.subtract(list(x['cum_sum days_before_product_ordered'].values)[0][-2],list(x['cum_sum days_before_product_ordered'].values)[0][-3]) if len(list(x['cum_sum days_before_product_ordered'].values)[0]) > 2 and list(x['cum_sum days_before_product_ordered'].values)[0][-3]>2 else list(x['cum_sum days_before_product_ordered'].values)[0][-2] if len(list(x['cum_sum days_before_product_ordered'].values)[0]) > 2 and np.isnan(list(x['cum_sum days_before_product_ordered'].values)[0][-3]) else np.NAN)\n",
    "list_days['days_before_product_ordered-3'] = list_days.groupby(['user_id','product_id']).progress_apply(lambda x: np.subtract(list(x['cum_sum days_before_product_ordered'].values)[0][-3],list(x['cum_sum days_before_product_ordered'].values)[0][-4]) if len(list(x['cum_sum days_before_product_ordered'].values)[0]) > 3 and list(x['cum_sum days_before_product_ordered'].values)[0][-4]>3 else list(x['cum_sum days_before_product_ordered'].values)[0][-3] if len(list(x['cum_sum days_before_product_ordered'].values)[0]) > 3 and np.isnan(list(x['cum_sum days_before_product_ordered'].values)[0][-4]) else np.NAN)\n",
    "list_days['days_before_product_ordered-4'] = list_days.groupby(['user_id','product_id']).progress_apply(lambda x: np.subtract(list(x['cum_sum days_before_product_ordered'].values)[0][-4],list(x['cum_sum days_before_product_ordered'].values)[0][-5]) if len(list(x['cum_sum days_before_product_ordered'].values)[0]) > 4 and list(x['cum_sum days_before_product_ordered'].values)[0][-5]>4 else list(x['cum_sum days_before_product_ordered'].values)[0][-4] if len(list(x['cum_sum days_before_product_ordered'].values)[0]) > 4 and np.isnan(list(x['cum_sum days_before_product_ordered'].values)[0][-5]) else np.NAN)\n",
    "list_days['days_before_product_ordered_mean'] = list_days.groupby(['user_id','product_id']).progress_apply(lambda x: np.nanmean(list(x['cum_sum days_before_product_ordered'].values)[0]))\n",
    "list_days['days_before_product_ordered_median'] = list_days.groupby(['user_id','product_id']).progress_apply(lambda x: np.nanmedian(list(x['cum_sum days_before_product_ordered'].values)[0]))\n",
    "list_days.to_csv('list_days_final.csv')\n",
    "\n",
    "list_days = pd.read_csv('list_days_final.csv',usecols=['user_id','product_id','days_before_product_ordered-1','days_before_product_ordered-2','days_before_product_ordered-3','days_before_product_ordered-4','days_before_product_ordered_mean','days_before_product_ordered_median'])\n",
    "list_days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>unique_prod_in_department</th>\n",
       "      <th>department_product_reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  department_id  unique_prod_in_department  \\\n",
       "0        1              4                          4   \n",
       "1        1              7                          2   \n",
       "2        1             13                          1   \n",
       "3        1             14                          1   \n",
       "4        1             16                          5   \n",
       "\n",
       "   department_product_reordered  \n",
       "0                             1  \n",
       "1                            11  \n",
       "2                             0  \n",
       "3                             2  \n",
       "4                             8  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features on user_id and Departments\n",
    "\n",
    "orders_prior = orders.merge(order_prior,on='order_id')[['order_id', 'user_id', 'product_id','reordered']]\n",
    "orders_prior_department_reordered = orders_prior.merge(products,on='product_id').drop_duplicates()[['user_id','order_id','product_id','department_id','reordered']]\n",
    "orders_prior_department_reordered = orders_prior_department_reordered.groupby(['user_id','department_id']).agg({'product_id':'nunique','reordered':'sum'})\n",
    "orders_prior_department_reordered = orders_prior_department_reordered.rename(columns={'product_id':'unique_prod_in_department','reordered':'department_product_reordered'})\n",
    "orders_prior_department_reordered.to_csv('orders_prior_department_reordered.csv')\n",
    "\n",
    "orders_prior_department_reordered = pd.read_csv('orders_prior_department_reordered.csv')\n",
    "orders_prior_department_reordered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>unique_prod_in_aisle</th>\n",
       "      <th>aisle_product_reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  aisle_id  unique_prod_in_aisle  aisle_product_reordered\n",
       "0        1        21                     1                        7\n",
       "1        1        23                     2                       10\n",
       "2        1        24                     4                        1\n",
       "3        1        45                     1                        0\n",
       "4        1        53                     1                        1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features on user_id and aisle\n",
    "\n",
    "orders_prior = orders.merge(order_prior,on='order_id')[['order_id', 'user_id', 'product_id','reordered']]\n",
    "orders_prior_aisle_reordered = orders_prior.merge(products,on='product_id').drop_duplicates()[['user_id','order_id','product_id','aisle_id','reordered']]\n",
    "orders_prior_aisle_reordered = orders_prior_aisle_reordered.groupby(['user_id','aisle_id']).agg({'product_id':'nunique','reordered':'sum'})\n",
    "orders_prior_aisle_reordered = orders_prior_aisle_reordered.rename(columns={'product_id':'unique_prod_in_aisle','reordered':'aisle_product_reordered'})\n",
    "orders_prior_aisle_reordered.to_csv('orders_prior_aisle_reordered.csv')\n",
    "\n",
    "orders_prior_aisle_reordered = pd.read_csv('orders_prior_aisle_reordered.csv')\n",
    "orders_prior_aisle_reordered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Reorder_product_prob</th>\n",
       "      <th>addToCartNumber_NumberOfOrder</th>\n",
       "      <th>add_to_cart_order_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613391</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>5.801836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.109877</td>\n",
       "      <td>9.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.732852</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>6.415162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.028898</td>\n",
       "      <td>9.507599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.431111</td>\n",
       "      <td>6.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Reorder_product_prob addToCartNumber_NumberOfOrder  \\\n",
       "                                                                \n",
       "product_id                                                      \n",
       "1                      0.613391                      0.003133   \n",
       "2                      0.133333                      0.109877   \n",
       "3                      0.732852                      0.023159   \n",
       "4                      0.446809                      0.028898   \n",
       "5                      0.600000                      0.431111   \n",
       "\n",
       "           add_to_cart_order_mean  \n",
       "                                   \n",
       "product_id                         \n",
       "1                        5.801836  \n",
       "2                        9.888889  \n",
       "3                        6.415162  \n",
       "4                        9.507599  \n",
       "5                        6.466667  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features on Product_id, add_to_cart_order, reordered\n",
    "\n",
    "productFeat = order_prior.groupby('product_id').agg({'add_to_cart_order':'mean', 'reordered':['sum','size']})\n",
    "productFeat['Reorder_product_prob'] = productFeat['reordered']['sum']/productFeat['reordered']['size']\n",
    "productFeat['addToCartNumber_NumberOfOrder'] = productFeat['add_to_cart_order']['mean']/productFeat['reordered']['size']\n",
    "productFeat['add_to_cart_order_mean'] = productFeat['add_to_cart_order']['mean']\n",
    "productFeat = productFeat.drop(['add_to_cart_order','reordered'],axis=1)\n",
    "productFeat.columns = ['Reorder_product_prob','addToCartNumber_NumberOfOrder', 'add_to_cart_order_mean']\n",
    "productFeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_orders_count</th>\n",
       "      <th>user_since</th>\n",
       "      <th>user_mean_days_since_prior_order</th>\n",
       "      <th>user_median_days_since_prior_order</th>\n",
       "      <th>unique_prod</th>\n",
       "      <th>NumberTimeProductsOrdered</th>\n",
       "      <th>user_reorder_ratio</th>\n",
       "      <th>Avergae_Basket_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>176.0</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>5.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>198.0</td>\n",
       "      <td>15.230769</td>\n",
       "      <td>13.0</td>\n",
       "      <td>102</td>\n",
       "      <td>195</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>13.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>133.0</td>\n",
       "      <td>12.090909</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_orders_count  user_since  user_mean_days_since_prior_order  \\\n",
       "user_id                                                                    \n",
       "1                       10       176.0                         19.555556   \n",
       "2                       14       198.0                         15.230769   \n",
       "3                       12       133.0                         12.090909   \n",
       "4                        5        55.0                         13.750000   \n",
       "5                        4        40.0                         13.333333   \n",
       "\n",
       "         user_median_days_since_prior_order  unique_prod  \\\n",
       "user_id                                                    \n",
       "1                                      20.0           18   \n",
       "2                                      13.0          102   \n",
       "3                                      11.0           33   \n",
       "4                                      17.0           17   \n",
       "5                                      11.0           23   \n",
       "\n",
       "         NumberTimeProductsOrdered  user_reorder_ratio  Avergae_Basket_size  \n",
       "user_id                                                                      \n",
       "1                               59            0.694915             5.900000  \n",
       "2                              195            0.476923            13.928571  \n",
       "3                               88            0.625000             7.333333  \n",
       "4                               18            0.055556             3.600000  \n",
       "5                               37            0.378378             9.250000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features on user_id, orders, products and days_since_prior_order\n",
    "\n",
    "# features on user_id, orders and days_since_prior_order\n",
    "user_order_merged = orders.merge(order_prior,on='order_id')[['order_id','user_id','days_since_prior_order']]\n",
    "here = user_order_merged.groupby(['order_id']).agg('max')\n",
    "here1 = here.groupby('user_id').agg({'user_id':'count','days_since_prior_order':['sum','mean','median']})\n",
    "here1.columns = here1.columns.levels[1]\n",
    "here1 = here1.rename(columns={'count':'user_orders_count','sum':'user_median_days_since_prior_order','mean':'user_since','median':'user_mean_days_since_prior_order'})\n",
    "\n",
    "# User Product Features\n",
    "user_product_merged = orders.merge(order_prior,on='order_id')\n",
    "user_product = user_product_merged.groupby('user_id').agg({'product_id':['nunique','size'],'reordered':['sum','count']})\n",
    "user_product.columns = user_product.columns.levels[1]\n",
    "user_product['user_reorder_ratio'] = user_product['size']/user_product['sum']\n",
    "user_product = user_product.drop(['size','sum'],axis=1).rename(columns={'count':'unique_prod','nunique':'NumberTimeProductsOrdered'})\n",
    "\n",
    "# merge both the DataFrames\n",
    "user_feat1 = here1.merge(user_product,on='user_id')\n",
    "user_feat1['Avergae_Basket_size'] = user_feat1['NumberTimeProductsOrdered']/user_feat1['user_orders_count']\n",
    "user_feat1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_unique_users_for_product</th>\n",
       "      <th>number_of_unique_users_for_product_reordered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>716</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            number_of_unique_users_for_product  \\\n",
       "product_id                                       \n",
       "1                                          716   \n",
       "2                                           78   \n",
       "3                                           74   \n",
       "4                                          182   \n",
       "5                                            6   \n",
       "\n",
       "            number_of_unique_users_for_product_reordered  \n",
       "product_id                                                \n",
       "1                                                    276  \n",
       "2                                                      8  \n",
       "3                                                     36  \n",
       "4                                                     64  \n",
       "5                                                      4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features on product_id and users\n",
    "\n",
    "user_order_merged = orders.merge(order_prior,on='order_id')\n",
    "number_of_unique_users_for_product = user_order_merged.groupby('product_id').agg({'user_id':'nunique'})\n",
    "number_of_unique_users_for_product_reordered = user_order_merged.groupby(['product_id','user_id']).agg({'reordered':'max'})\n",
    "number_of_unique_users_for_product_reordered = number_of_unique_users_for_product_reordered.groupby('product_id').agg({'reordered':'sum'})\n",
    "product_features1 = number_of_unique_users_for_product.rename(columns={'user_id':'number_of_unique_users_for_product'}).copy()\n",
    "product_features1['number_of_unique_users_for_product_reordered'] = number_of_unique_users_for_product_reordered['reordered'].values\n",
    "product_features1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>week_product_reordered</th>\n",
       "      <th>week_product_ordered</th>\n",
       "      <th>week_product_reordered_ration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_dow</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">196</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              week_product_reordered  week_product_ordered  \\\n",
       "user_id product_id order_dow                                                 \n",
       "1       196        1                               3                     3   \n",
       "                   2                               1                     2   \n",
       "                   3                               2                     2   \n",
       "                   4                               3                     3   \n",
       "        10258      1                               3                     3   \n",
       "\n",
       "                              week_product_reordered_ration  \n",
       "user_id product_id order_dow                                 \n",
       "1       196        1                                    1.0  \n",
       "                   2                                    0.5  \n",
       "                   3                                    1.0  \n",
       "                   4                                    1.0  \n",
       "        10258      1                                    1.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features on user_id, product_id, order_dow and orders\n",
    "\n",
    "order_prior_merged = order_prior.merge(orders,on=\"order_id\")\n",
    "here1 = order_prior_merged.groupby(['user_id','product_id','order_dow']).agg({'reordered':['sum','size']})\n",
    "here1.columns = here1.columns.levels[1]\n",
    "here1 = here1.rename(columns={'sum':'week_product_reordered','size':'week_product_ordered',})\n",
    "here1['week_product_reordered_ration'] = here1['week_product_reordered']/here1['week_product_ordered']\n",
    "here1 = here1.fillna(value=0.0)\n",
    "here1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prod_orders</th>\n",
       "      <th>prod_ordersBYtotal_orders</th>\n",
       "      <th>product_ordered_last</th>\n",
       "      <th>product_ordered_first</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>196</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13032</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    prod_orders  prod_ordersBYtotal_orders  \\\n",
       "user_id product_id                                           \n",
       "1       196                  10                        1.0   \n",
       "        10258                 9                        0.9   \n",
       "        10326                 1                        0.1   \n",
       "        12427                10                        1.0   \n",
       "        13032                 3                        0.3   \n",
       "\n",
       "                    product_ordered_last  product_ordered_first  \n",
       "user_id product_id                                               \n",
       "1       196                            0                      9  \n",
       "        10258                          0                      8  \n",
       "        10326                          5                      5  \n",
       "        12427                          0                      9  \n",
       "        13032                          0                      8  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features on user_id, product_id and Order_id\n",
    "# prod_ordersBYtotal_orders - number of products ordered in those orders the divide by number of orders done by user \n",
    "# product_ordered_last - difference of order number from last order with that product and total orders by the user\n",
    "# product_ordered_first - difference of order number from first order with that product and total orders by the user\n",
    "\n",
    "order_prior_merged = order_prior.merge(orders,on=\"order_id\")\n",
    "user_product_order_temp = order_prior_merged.groupby(['user_id', 'product_id']).agg({'user_id':'size','order_number':['min','max']})\n",
    "user_product_order_temp.columns = user_product_order_temp.columns.droplevel(0)\n",
    "user_product_order['prod_ordersBYtotal_orders'] = user_product_order_temp['size']/user_feat1['user_orders_count']\n",
    "user_product_order['product_ordered_last'] = user_feat1['user_orders_count'] - user_product_order_temp['max']\n",
    "user_product_order['product_ordered_first'] = user_feat1['user_orders_count'] - user_product_order_temp['min']\n",
    "user_product_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prod_min_orderNumber</th>\n",
       "      <th>prod_max_orderNumber</th>\n",
       "      <th>prod_cart_mean</th>\n",
       "      <th>days_since_prior_order_mean</th>\n",
       "      <th>order_dow_mean</th>\n",
       "      <th>order_hour_of_day_mean</th>\n",
       "      <th>add_to_cart_order_inverse_mean</th>\n",
       "      <th>add_to_cart_order_relative_mean</th>\n",
       "      <th>reordered_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.245278</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.562037</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13032</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    prod_min_orderNumber  prod_max_orderNumber  \\\n",
       "user_id product_id                                               \n",
       "1       196                            1                    10   \n",
       "        10258                          2                    10   \n",
       "        10326                          5                     5   \n",
       "        12427                          1                    10   \n",
       "        13032                          2                    10   \n",
       "\n",
       "                    prod_cart_mean  days_since_prior_order_mean  \\\n",
       "user_id product_id                                                \n",
       "1       196               1.400000                    19.555556   \n",
       "        10258             3.333333                    19.555556   \n",
       "        10326             5.000000                    28.000000   \n",
       "        12427             3.300000                    19.555556   \n",
       "        13032             6.333333                    21.666667   \n",
       "\n",
       "                    order_dow_mean  order_hour_of_day_mean  \\\n",
       "user_id product_id                                           \n",
       "1       196               2.500000               10.300000   \n",
       "        10258             2.555556               10.555556   \n",
       "        10326             4.000000               15.000000   \n",
       "        12427             2.500000               10.300000   \n",
       "        13032             2.666667                8.000000   \n",
       "\n",
       "                    add_to_cart_order_inverse_mean  \\\n",
       "user_id product_id                                   \n",
       "1       196                               4.500000   \n",
       "        10258                             2.666667   \n",
       "        10326                             3.000000   \n",
       "        12427                             2.600000   \n",
       "        13032                             0.333333   \n",
       "\n",
       "                    add_to_cart_order_relative_mean  reordered_sum  \n",
       "user_id product_id                                                  \n",
       "1       196                                0.245278              9  \n",
       "        10258                              0.562037              8  \n",
       "        10326                              0.625000              0  \n",
       "        12427                              0.541667              9  \n",
       "        13032                              0.962963              2  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature on order_id, product_id and add_to_cart_order\n",
    "order_prior_merged = order_prior.merge(orders,on=\"order_id\")\n",
    "temp1 = order_prior_merged.groupby('order_id').agg({'add_to_cart_order':'max'}).rename(columns={'add_to_cart_order':'basket_size'})\n",
    "temp1 = temp1.merge(order_prior_merged, on='order_id')\n",
    "temp1['add_to_cart_order_inverse'] = temp1['basket_size']-temp1['add_to_cart_order']\n",
    "temp1['add_to_cart_order_relative'] = temp1['add_to_cart_order']/temp1['basket_size']\n",
    "temp1.head()\n",
    "\n",
    "# get mean, min, max and size features\n",
    "temp_data = temp1.groupby(['user_id', 'product_id']).agg({\n",
    "                                                       'order_number': ['min', 'max'],\n",
    "                                                       'add_to_cart_order': 'mean',\n",
    "                                                       'days_since_prior_order': 'mean',\n",
    "                                                       'order_dow':'mean',\n",
    "                                                       'order_hour_of_day': 'mean',\n",
    "                                                       'add_to_cart_order_inverse': 'mean',\n",
    "                                                       'add_to_cart_order_relative': 'mean',\n",
    "                                                       'reordered':'sum'})\n",
    "\n",
    "temp_data.columns = temp_data.columns.droplevel(0)\n",
    "temp_data.columns = ['prod_min_orderNumber', 'prod_max_orderNumber', 'prod_cart_mean',\n",
    "                         'days_since_prior_order_mean', 'order_dow_mean','order_hour_of_day_mean',\n",
    "                'add_to_cart_order_inverse_mean','add_to_cart_order_relative_mean','reordered_sum']\n",
    "temp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.238604</td>\n",
       "      <td>1.467404</td>\n",
       "      <td>1.161555</td>\n",
       "      <td>0.257020</td>\n",
       "      <td>0.262400</td>\n",
       "      <td>-0.472287</td>\n",
       "      <td>-0.498063</td>\n",
       "      <td>0.617533</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>0.331204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225085</td>\n",
       "      <td>1.292168</td>\n",
       "      <td>0.023675</td>\n",
       "      <td>2.212941</td>\n",
       "      <td>0.192866</td>\n",
       "      <td>-0.677150</td>\n",
       "      <td>0.220644</td>\n",
       "      <td>-0.549214</td>\n",
       "      <td>0.328943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.604643</td>\n",
       "      <td>0.315079</td>\n",
       "      <td>-0.612005</td>\n",
       "      <td>-0.698891</td>\n",
       "      <td>-0.060198</td>\n",
       "      <td>-0.258082</td>\n",
       "      <td>0.527160</td>\n",
       "      <td>-0.782410</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>-0.357846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.597167</td>\n",
       "      <td>-0.401836</td>\n",
       "      <td>-0.673824</td>\n",
       "      <td>0.121742</td>\n",
       "      <td>0.988963</td>\n",
       "      <td>-0.378714</td>\n",
       "      <td>0.429604</td>\n",
       "      <td>-0.675098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.055381</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>-0.301937</td>\n",
       "      <td>-0.741934</td>\n",
       "      <td>0.294994</td>\n",
       "      <td>-0.908531</td>\n",
       "      <td>-0.095207</td>\n",
       "      <td>-0.549281</td>\n",
       "      <td>-0.978078</td>\n",
       "      <td>0.651974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021210</td>\n",
       "      <td>-0.214384</td>\n",
       "      <td>-0.812447</td>\n",
       "      <td>-0.221399</td>\n",
       "      <td>0.424221</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.594096</td>\n",
       "      <td>-0.665587</td>\n",
       "      <td>-0.555554</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.226095</td>\n",
       "      <td>0.666498</td>\n",
       "      <td>0.096109</td>\n",
       "      <td>0.504644</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>-0.390370</td>\n",
       "      <td>-0.867693</td>\n",
       "      <td>0.195124</td>\n",
       "      <td>0.540179</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593099</td>\n",
       "      <td>0.570194</td>\n",
       "      <td>-0.138637</td>\n",
       "      <td>-0.736523</td>\n",
       "      <td>-0.268775</td>\n",
       "      <td>0.512141</td>\n",
       "      <td>-0.835119</td>\n",
       "      <td>-0.139976</td>\n",
       "      <td>0.540997</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.327244</td>\n",
       "      <td>0.582291</td>\n",
       "      <td>-0.109301</td>\n",
       "      <td>-0.122129</td>\n",
       "      <td>-0.402943</td>\n",
       "      <td>-0.896186</td>\n",
       "      <td>0.042546</td>\n",
       "      <td>-0.195300</td>\n",
       "      <td>-0.409419</td>\n",
       "      <td>-0.314801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171655</td>\n",
       "      <td>0.409905</td>\n",
       "      <td>0.905563</td>\n",
       "      <td>-0.796210</td>\n",
       "      <td>0.206565</td>\n",
       "      <td>0.470135</td>\n",
       "      <td>-0.127850</td>\n",
       "      <td>-0.213620</td>\n",
       "      <td>0.665445</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.238604  1.467404  1.161555  0.257020  0.262400 -0.472287 -0.498063   \n",
       "1  0.604643  0.315079 -0.612005 -0.698891 -0.060198 -0.258082  0.527160   \n",
       "2 -0.055381 -0.702918 -0.301937 -0.741934  0.294994 -0.908531 -0.095207   \n",
       "3 -0.226095  0.666498  0.096109  0.504644  0.005883 -0.390370 -0.867693   \n",
       "4 -0.327244  0.582291 -0.109301 -0.122129 -0.402943 -0.896186  0.042546   \n",
       "\n",
       "          7         8         9  ...        23        24        25        26  \\\n",
       "0  0.617533  0.143423  0.331204  ... -0.225085  1.292168  0.023675  2.212941   \n",
       "1 -0.782410  0.104015 -0.357846  ...  0.001443  0.597167 -0.401836 -0.673824   \n",
       "2 -0.549281 -0.978078  0.651974  ...  0.021210 -0.214384 -0.812447 -0.221399   \n",
       "3  0.195124  0.540179  0.581654  ...  0.593099  0.570194 -0.138637 -0.736523   \n",
       "4 -0.195300 -0.409419 -0.314801  ... -0.171655  0.409905  0.905563 -0.796210   \n",
       "\n",
       "         27        28        29        30        31  product_id  \n",
       "0  0.192866 -0.677150  0.220644 -0.549214  0.328943           1  \n",
       "1  0.121742  0.988963 -0.378714  0.429604 -0.675098           2  \n",
       "2  0.424221  0.276618  0.594096 -0.665587 -0.555554           3  \n",
       "3 -0.268775  0.512141 -0.835119 -0.139976  0.540997           4  \n",
       "4  0.206565  0.470135 -0.127850 -0.213620  0.665445           5  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# product embedding uploaded by one of the competitor on kaggle \n",
    "# https://www.kaggle.com/c/instacart-market-basket-analysis/discussion/37697\n",
    "# the product embedding is created from orders Data \n",
    "\n",
    "product_embeddings = pd.read_pickle('data/product_embeddings.pkl')\n",
    "embedings = list(range(32))\n",
    "product_embeddings = product_embeddings[embedings + ['product_id']]\n",
    "product_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the dataframes\n",
    "data = labels[labels['eval_set']==\"train\"]\n",
    "data = data.merge(orders,on=\"order_id\")\n",
    "data = data.merge(products,on=\"product_id\")\n",
    "\n",
    "data = data.merge(orders_prior_aisle_reordered,on=['user_id', 'aisle_id'])\n",
    "data = data.merge(orders_prior_department_reordered,on=['user_id', 'department_id'])\n",
    "\n",
    "data = data.merge(product_features1,on='product_id')\n",
    "data = data.merge(product_embeddings,on='product_id')\n",
    "\n",
    "user_prod = list_days.merge(user_product_order,on=['user_id','product_id'])\n",
    "user_prod = user_prod.merge(temp_data,on=['user_id','product_id'])\n",
    "data = data.merge(user_prod,on=['user_id','product_id'])\n",
    "data = data.merge(here1,on=['user_id','product_id','order_dow'], how='left')\n",
    "data_train = data.merge(user_feat1,on='user_id')\n",
    "data_train.to_csv('my_final/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the features\n",
    "data_train = pd.read_csv('my_final/data.csv')\n",
    "labels_train = data_train['reordered']\n",
    "\n",
    "# filling NaN values as -1\n",
    "data_train = data_train.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data User_id wise\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "train_inds, test_inds = next(GroupShuffleSplit(test_size=.3, n_splits=1, random_state = 42).split(data_train, groups=data_train['user_id']))\n",
    "\n",
    "data_train = data_train.drop(['Unnamed: 0', 'order_id','eval_set_x','eval_set_y','reordered','product_name','user_id','product_id','order_number','order_dow','order_hour_of_day','days_since_prior_order','aisle_id','department_id'],axis=1)\n",
    "\n",
    "X_train1 = data_train.iloc[train_inds]\n",
    "y_train1 = labels_train.iloc[train_inds]\n",
    "X_cv1 = data_train.iloc[test_inds]\n",
    "y_cv1 = labels_train.iloc[train_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_clf = SVC(class_weight='balanced').fit(X_train1, y_train1)\n",
    "pred_Xcv = svc_clf.predict(X_cv)\n",
    "print(\"Confusion Matrix : \", confusion_matrix(y_cv, pred_Xcv))\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_cv, pred_Xcv), ['Pred_0','Pred_1'], ['Actual_0','Actual_1'])\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
    "\n",
    "plt.show()\n",
    "print(\"F1 score : \", f1_score(y_cv, pred_Xcv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 68)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 51)                3519      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 51)                204       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 44)                2288      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44)                176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 34)                1530      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 44)                1540      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 44)                176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 51)                2295      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 51)                204       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 68)                3536      \n",
      "=================================================================\n",
      "Total params: 15,468\n",
      "Trainable params: 15,088\n",
      "Non-trainable params: 380\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "92620/92620 [==============================] - 423s 5ms/step - loss: 334239.5938 - val_loss: 169001.8281\n",
      "Epoch 2/10\n",
      "92620/92620 [==============================] - 410s 4ms/step - loss: 9676.4180 - val_loss: 99034.6484\n",
      "Epoch 3/10\n",
      "92620/92620 [==============================] - 391s 4ms/step - loss: 6766.5742 - val_loss: 86417.6953\n",
      "Epoch 4/10\n",
      "92620/92620 [==============================] - 374s 4ms/step - loss: 5410.8945 - val_loss: 93925.1250\n",
      "Epoch 5/10\n",
      "92620/92620 [==============================] - 374s 4ms/step - loss: 4637.0586 - val_loss: 58491.9180\n",
      "Epoch 6/10\n",
      "92620/92620 [==============================] - 374s 4ms/step - loss: 4156.4043 - val_loss: 65781.3594\n",
      "Epoch 7/10\n",
      "92620/92620 [==============================] - 380s 4ms/step - loss: 3752.0627 - val_loss: 48979.5508\n",
      "Epoch 8/10\n",
      "92620/92620 [==============================] - 375s 4ms/step - loss: 3493.0457 - val_loss: 88854.0781\n",
      "Epoch 9/10\n",
      "92620/92620 [==============================] - 372s 4ms/step - loss: 3267.2681 - val_loss: 50273.2500\n",
      "Epoch 10/10\n",
      "92620/92620 [==============================] - 367s 4ms/step - loss: 2982.4324 - val_loss: 60824.1055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/autoencoder-for-classification/\n",
    "# Autoencoder for classification with compression in the bottleneck layer\n",
    "# In this example I have not tried to normalize the data.\n",
    "# Autoencoder without Normalization\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train1, X_cv1, y_train1, y_cv1\n",
    "# scale data\n",
    "n_inputs = X_train.shape[1]\n",
    "\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*0.75)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs*0.65)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs*0.65)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*0.75)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# plot the autoencoder\n",
    "plot_model(model, 'autoencoder_withoutNorm_compress.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "model.summary()\n",
    "plot_model(model, 'autoencoder_withoutNorm.png', show_shapes=True)\n",
    "history = model.fit(X_train, X_train, epochs=10, batch_size=64, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "plot_model(encoder, 'autoencoder_withoutNorm_compress.png', show_shapes=True)\n",
    "# save the encoder to file\n",
    "encoder.save('autoencoder_withoutNorm.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 68)]              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 51)                3519      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 51)                204       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 44)                2288      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 44)                176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 34)                1530      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 44)                1540      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 44)                176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 51)                2295      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 51)                204       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 68)                3536      \n",
      "=================================================================\n",
      "Total params: 15,468\n",
      "Trainable params: 15,088\n",
      "Non-trainable params: 380\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "92620/92620 [==============================] - 386s 4ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 2/5\n",
      "92620/92620 [==============================] - 369s 4ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "92620/92620 [==============================] - 1936s 21ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "92620/92620 [==============================] - 387s 4ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "92620/92620 [==============================] - 383s 4ms/step - loss: 0.0024 - val_loss: 0.0020\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# autoencoder with normalization\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train1, X_cv1, y_train1, y_cv1\n",
    "# scale data\n",
    "n_inputs = X_train.shape[1]\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "# define encoder\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*0.75)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs*0.65)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs*0.65)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs*0.75)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# plot the autoencoder\n",
    "plot_model(model, 'autoencoderwithNorm_compress.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "model.summary()\n",
    "plot_model(model, 'autoencoderwithNorm.png', show_shapes=True)\n",
    "history = model.fit(X_train, X_train, epochs=5, batch_size=64, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "plot_model(encoder, 'autoencoderwithNorm_compress.png', show_shapes=True)\n",
    "# save the encoder to file\n",
    "encoder.save('autoencoderwithNorm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>After Applying the ML model I am gonne see which type of Autoencoder I am gonne use or if I am even gonne use the autoencoders or not.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :  0.16354973285255797\n"
     ]
    }
   ],
   "source": [
    "# Random Model\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data_train = pd.read_csv('my_final/data.csv')\n",
    "labels_train = data_train['reordered']\n",
    "\n",
    "random_label = []\n",
    "for i in range(len(labels_train)):\n",
    "    random_label.append(bool(random.getrandbits(1)))\n",
    "\n",
    "print(\"F1 score : \", f1_score(labels_train, random_label))\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 score : \", f1_score(labels_train, random_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
